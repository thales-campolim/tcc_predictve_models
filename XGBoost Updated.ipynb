{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import unicodedata\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_csv_files(folder_path, csv_files):\n",
    "    df_list = []\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        print(f\"Reading {file_path}\")\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, delimiter=',', on_bad_lines='skip')\n",
    "            df_list.append(df)\n",
    "        except pd.errors.ParserError as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "    \n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_csvs_in_folder(folder_path):\n",
    "    csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "    df_list = []\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        print(f\"Reading {file_path}\")\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, delimiter=',', on_bad_lines='skip')\n",
    "            df_list.append(df)\n",
    "        except pd.errors.ParserError as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "    \n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_model(features, labels):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Initialize and train the Random Forest model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    \n",
    "    # Generate and print the classification report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "    \n",
    "    # Print the accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    \n",
    "    return rf_model, report, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading D:/tcc_predictve_models\\campeonato_brasileiro_serie_a_2013.csv\n",
      "Reading D:/tcc_predictve_models\\campeonato_brasileiro_serie_a_2014.csv\n",
      "Reading D:/tcc_predictve_models\\campeonato_brasileiro_serie_a_2015.csv\n",
      "Reading D:/tcc_predictve_models\\campeonato_brasileiro_serie_a_2016.csv\n",
      "Reading D:/tcc_predictve_models\\campeonato_brasileiro_serie_a_2017.csv\n",
      "Reading D:/tcc_predictve_models\\campeonato_brasileiro_serie_a_2018.csv\n",
      "Reading D:/tcc_predictve_models\\campeonato_brasileiro_serie_a_2019.csv\n",
      "Reading D:/tcc_predictve_models\\campeonato_brasileiro_serie_a_2020.csv\n",
      "Reading D:/tcc_predictve_models\\campeonato_brasileiro_serie_a_2021.csv\n",
      "Reading D:/tcc_predictve_models\\campeonato_brasileiro_serie_a_2022.csv\n",
      "Reading D:/tcc_predictve_models\\campeonato_brasileiro_serie_a_2023.csv\n",
      "Reading D:/tcc_predictve_models\\campeonato_brasileiro_serie_a_2024.csv\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'D:/tcc_predictve_models'\n",
    "combined_df = read_all_csvs_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date_GMT</th>\n",
       "      <th>status</th>\n",
       "      <th>attendance</th>\n",
       "      <th>home_team_name</th>\n",
       "      <th>away_team_name</th>\n",
       "      <th>referee</th>\n",
       "      <th>Game Week</th>\n",
       "      <th>Pre-Match PPG (Home)</th>\n",
       "      <th>Pre-Match PPG (Away)</th>\n",
       "      <th>...</th>\n",
       "      <th>odds_ft_home_team_win</th>\n",
       "      <th>odds_ft_draw</th>\n",
       "      <th>odds_ft_away_team_win</th>\n",
       "      <th>odds_ft_over15</th>\n",
       "      <th>odds_ft_over25</th>\n",
       "      <th>odds_ft_over35</th>\n",
       "      <th>odds_ft_over45</th>\n",
       "      <th>odds_btts_yes</th>\n",
       "      <th>odds_btts_no</th>\n",
       "      <th>stadium_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1369517400</td>\n",
       "      <td>May 25 2013 - 9:30pm</td>\n",
       "      <td>complete</td>\n",
       "      <td>11099.0</td>\n",
       "      <td>Vasco da Gama</td>\n",
       "      <td>Portuguesa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.80</td>\n",
       "      <td>5.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Estádio Club de Regatas Vasco da Gama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1369517400</td>\n",
       "      <td>May 25 2013 - 9:30pm</td>\n",
       "      <td>complete</td>\n",
       "      <td>8955.0</td>\n",
       "      <td>Vitória</td>\n",
       "      <td>Internacional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.85</td>\n",
       "      <td>3.34</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Arena Fonte Nova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1369526400</td>\n",
       "      <td>May 26 2013 - 12:00am</td>\n",
       "      <td>complete</td>\n",
       "      <td>29295.0</td>\n",
       "      <td>Corinthians</td>\n",
       "      <td>Botafogo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.99</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Estádio Municipal Paulo Machado de Carvalho (S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1369594800</td>\n",
       "      <td>May 26 2013 - 7:00pm</td>\n",
       "      <td>complete</td>\n",
       "      <td>9560.0</td>\n",
       "      <td>Grêmio</td>\n",
       "      <td>Náutico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.50</td>\n",
       "      <td>4.38</td>\n",
       "      <td>7.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Estádio Alfredo Jaconi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1369594800</td>\n",
       "      <td>May 26 2013 - 7:00pm</td>\n",
       "      <td>complete</td>\n",
       "      <td>6267.0</td>\n",
       "      <td>Ponte Preta</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.18</td>\n",
       "      <td>3.33</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Estádio Moisés Lucarelli</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    timestamp               date_GMT    status  attendance home_team_name  \\\n",
       "0  1369517400   May 25 2013 - 9:30pm  complete     11099.0  Vasco da Gama   \n",
       "1  1369517400   May 25 2013 - 9:30pm  complete      8955.0        Vitória   \n",
       "2  1369526400  May 26 2013 - 12:00am  complete     29295.0    Corinthians   \n",
       "3  1369594800   May 26 2013 - 7:00pm  complete      9560.0         Grêmio   \n",
       "4  1369594800   May 26 2013 - 7:00pm  complete      6267.0    Ponte Preta   \n",
       "\n",
       "  away_team_name referee  Game Week  Pre-Match PPG (Home)  \\\n",
       "0     Portuguesa     NaN          1                   0.0   \n",
       "1  Internacional     NaN          1                   0.0   \n",
       "2       Botafogo     NaN          1                   0.0   \n",
       "3        Náutico     NaN          1                   0.0   \n",
       "4      São Paulo     NaN          1                   0.0   \n",
       "\n",
       "   Pre-Match PPG (Away)  ...  odds_ft_home_team_win  odds_ft_draw  \\\n",
       "0                   0.0  ...                   1.70          3.80   \n",
       "1                   0.0  ...                   2.85          3.34   \n",
       "2                   0.0  ...                   1.99          3.50   \n",
       "3                   0.0  ...                   1.50          4.38   \n",
       "4                   0.0  ...                   3.18          3.33   \n",
       "\n",
       "   odds_ft_away_team_win  odds_ft_over15  odds_ft_over25  odds_ft_over35  \\\n",
       "0                   5.60             0.0             0.0             0.0   \n",
       "1                   2.63             0.0             0.0             0.0   \n",
       "2                   4.12             0.0             0.0             0.0   \n",
       "3                   7.38             0.0             0.0             0.0   \n",
       "4                   2.41             0.0             0.0             0.0   \n",
       "\n",
       "   odds_ft_over45  odds_btts_yes odds_btts_no  \\\n",
       "0             0.0            0.0          0.0   \n",
       "1             0.0            0.0          0.0   \n",
       "2             0.0            0.0          0.0   \n",
       "3             0.0            0.0          0.0   \n",
       "4             0.0            0.0          0.0   \n",
       "\n",
       "                                        stadium_name  \n",
       "0              Estádio Club de Regatas Vasco da Gama  \n",
       "1                                   Arena Fonte Nova  \n",
       "2  Estádio Municipal Paulo Machado de Carvalho (S...  \n",
       "3                             Estádio Alfredo Jaconi  \n",
       "4                           Estádio Moisés Lucarelli  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thale\\AppData\\Local\\Temp\\ipykernel_10660\\719087000.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_df['result'] = features_df.apply(\n",
      "C:\\Users\\thale\\AppData\\Local\\Temp\\ipykernel_10660\\719087000.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_df['result_code'] = features_df['result'].map(mapping)\n"
     ]
    }
   ],
   "source": [
    "features_df = combined_df[['home_team_name', 'away_team_name', 'home_team_goal_count', 'away_team_goal_count', 'home_team_shots', 'home_team_shots_on_target', 'away_team_shots_on_target', 'away_team_fouls']]\n",
    "\n",
    "features_df['result'] = features_df.apply(\n",
    "    lambda row: (\n",
    "        'home winner' if row['home_team_goal_count'] > row['away_team_goal_count'] else \n",
    "        ('away winner' if row['home_team_goal_count'] < row['away_team_goal_count'] else 'draw')\n",
    "    ) if pd.notnull(row['home_team_goal_count']) and pd.notnull(row['away_team_goal_count']) else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "mapping = {'home winner': 0, 'away winner': 1, 'draw': 2}\n",
    "\n",
    "# Apply the mapping to the column\n",
    "features_df['result_code'] = features_df['result'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy encode the 'home_team_code' and 'away_team_code' columns\n",
    "dummies = pd.get_dummies(features_df[['home_team_name', 'away_team_name']], prefix=['home_team', 'away_team'], drop_first=True)\n",
    "\n",
    "# Convert dummy variables to 0 and 1\n",
    "dummies = dummies.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original columns and concatenate the dummy variables\n",
    "features_df = pd.concat([features_df.drop(['home_team_name', 'away_team_name'], axis=1), dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_names(df):\n",
    "    def clean_name(name):\n",
    "        # Convert to lowercase\n",
    "        name = name.lower()\n",
    "        # Replace spaces with underscores\n",
    "        name = name.replace(' ', '_')\n",
    "        # Remove accents\n",
    "        name = ''.join(\n",
    "            (c for c in unicodedata.normalize('NFD', name) \n",
    "            if unicodedata.category(c) != 'Mn')\n",
    "        )\n",
    "        # Replace any remaining non-alphanumeric characters with underscores\n",
    "        name = re.sub(r'\\W+', '_', name)\n",
    "        return name\n",
    "\n",
    "    # Apply the cleaning function to all column names\n",
    "    df.columns = [clean_name(col) for col in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the DataFrame\n",
    "features_df = clean_column_names(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = features_df['result_code']\n",
    "features_df = features_df.drop(['result', 'result_code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2187 candidates, totalling 6561 fits\n",
      "Best Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 100, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 0.7}\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       636\n",
      "           1       1.00      1.00      1.00       336\n",
      "           2       1.00      1.00      1.00       374\n",
      "\n",
      "    accuracy                           1.00      1346\n",
      "   macro avg       1.00      1.00      1.00      1346\n",
      "weighted avg       1.00      1.00      1.00      1346\n",
      "\n",
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'features' and 'labels' are already defined\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_df, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "xgboost = xgb.XGBClassifier(random_state=42, eval_metric='mlogloss')\n",
    "grid_search = GridSearchCV(estimator=xgboost, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "best_xgb = grid_search.best_estimator_\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
