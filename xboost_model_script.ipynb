{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eab169f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessed DataFrame head:\n",
      "   away_team_red_cards  home_team_shots  home_team_shots_on_target  \\\n",
      "0                    1                9                          2   \n",
      "1                    0               11                          2   \n",
      "2                    0               10                          6   \n",
      "3                    0               15                          7   \n",
      "4                    1               15                          5   \n",
      "\n",
      "   away_team_shots_on_target  away_team_fouls  result_code  \\\n",
      "0                          2               20            0   \n",
      "1                          7               10            2   \n",
      "2                          5               26            2   \n",
      "3                          4               15            0   \n",
      "4                          5               25            1   \n",
      "\n",
      "   home_team_name_atletico_go  home_team_name_atletico_mineiro  \\\n",
      "0                           0                                0   \n",
      "1                           0                                0   \n",
      "2                           0                                0   \n",
      "3                           0                                0   \n",
      "4                           0                                0   \n",
      "\n",
      "   home_team_name_atletico_pr  home_team_name_avai  ...  \\\n",
      "0                           0                    0  ...   \n",
      "1                           0                    0  ...   \n",
      "2                           0                    0  ...   \n",
      "3                           0                    0  ...   \n",
      "4                           0                    0  ...   \n",
      "\n",
      "   away_team_name_palmeiras  away_team_name_parana  \\\n",
      "0                         0                      0   \n",
      "1                         0                      0   \n",
      "2                         0                      0   \n",
      "3                         0                      0   \n",
      "4                         0                      0   \n",
      "\n",
      "   away_team_name_ponte_preta  away_team_name_portuguesa  \\\n",
      "0                           0                          1   \n",
      "1                           0                          0   \n",
      "2                           0                          0   \n",
      "3                           0                          0   \n",
      "4                           0                          0   \n",
      "\n",
      "   away_team_name_santa_cruz  away_team_name_santos  \\\n",
      "0                          0                      0   \n",
      "1                          0                      0   \n",
      "2                          0                      0   \n",
      "3                          0                      0   \n",
      "4                          0                      0   \n",
      "\n",
      "   away_team_name_sport_recife  away_team_name_sao_paulo  \\\n",
      "0                            0                         0   \n",
      "1                            0                         0   \n",
      "2                            0                         0   \n",
      "3                            0                         0   \n",
      "4                            0                         1   \n",
      "\n",
      "   away_team_name_vasco_da_gama  away_team_name_vitoria  \n",
      "0                             0                       0  \n",
      "1                             0                       0  \n",
      "2                             0                       0  \n",
      "3                             0                       0  \n",
      "4                             0                       0  \n",
      "\n",
      "[5 rows x 76 columns]\n",
      "\n",
      "Shape of preprocessed DataFrame: (4485, 76)\n",
      "\n",
      "Columns in preprocessed DataFrame: ['away_team_red_cards', 'home_team_shots', 'home_team_shots_on_target', 'away_team_shots_on_target', 'away_team_fouls', 'result_code', 'home_team_name_atletico_go', 'home_team_name_atletico_mineiro', 'home_team_name_atletico_pr', 'home_team_name_avai', 'home_team_name_bahia', 'home_team_name_botafogo', 'home_team_name_bragantino', 'home_team_name_csa', 'home_team_name_ceara', 'home_team_name_chapecoense', 'home_team_name_corinthians', 'home_team_name_coritiba', 'home_team_name_criciuma', 'home_team_name_cruzeiro', 'home_team_name_cuiaba', 'home_team_name_figueirense', 'home_team_name_flamengo', 'home_team_name_fluminense', 'home_team_name_fortaleza', 'home_team_name_goias', 'home_team_name_gremio', 'home_team_name_internacional', 'home_team_name_joinville', 'home_team_name_juventude', 'home_team_name_nautico', 'home_team_name_palmeiras', 'home_team_name_parana', 'home_team_name_ponte_preta', 'home_team_name_portuguesa', 'home_team_name_santa_cruz', 'home_team_name_santos', 'home_team_name_sport_recife', 'home_team_name_sao_paulo', 'home_team_name_vasco_da_gama', 'home_team_name_vitoria', 'away_team_name_atletico_go', 'away_team_name_atletico_mineiro', 'away_team_name_atletico_pr', 'away_team_name_avai', 'away_team_name_bahia', 'away_team_name_botafogo', 'away_team_name_bragantino', 'away_team_name_csa', 'away_team_name_ceara', 'away_team_name_chapecoense', 'away_team_name_corinthians', 'away_team_name_coritiba', 'away_team_name_criciuma', 'away_team_name_cruzeiro', 'away_team_name_cuiaba', 'away_team_name_figueirense', 'away_team_name_flamengo', 'away_team_name_fluminense', 'away_team_name_fortaleza', 'away_team_name_goias', 'away_team_name_gremio', 'away_team_name_internacional', 'away_team_name_joinville', 'away_team_name_juventude', 'away_team_name_nautico', 'away_team_name_palmeiras', 'away_team_name_parana', 'away_team_name_ponte_preta', 'away_team_name_portuguesa', 'away_team_name_santa_cruz', 'away_team_name_santos', 'away_team_name_sport_recife', 'away_team_name_sao_paulo', 'away_team_name_vasco_da_gama', 'away_team_name_vitoria']\n",
      "\n",
      "Value counts for target 'result_code':\n",
      "result_code\n",
      "0    2160\n",
      "2    1223\n",
      "1    1102\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train_and_tune_xgboost() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 178\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mValue counts for target \u001b[39m\u001b[33m'\u001b[39m\u001b[33mresult_code\u001b[39m\u001b[33m'\u001b[39m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdf_processed_data[\u001b[33m'\u001b[39m\u001b[33mresult_code\u001b[39m\u001b[33m'\u001b[39m].value_counts()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# Now, run the XGBoost training and tuning function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m best_model = \u001b[43mtrain_and_tune_xgboost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_processed_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclass_mapping_used\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[38;5;66;03m# The 'best_model' can now be used for further predictions or saved\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[38;5;66;03m# For example, to save the model:\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[38;5;66;03m# best_model.save_model(\"best_xgboost_model.json\") # [3]\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBest XGBoost model training and tuning complete.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: train_and_tune_xgboost() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# --- Your existing functions ---\n",
    "def get_csv_data():\n",
    "    df = pd.read_csv('df_2013_2024_camp_brasileiro.csv')\n",
    "    return df\n",
    "\n",
    "def define_target_variable(df):\n",
    "    df['result'] = df.apply(\n",
    "        lambda row: (\n",
    "            'home winner' if row['home_team_goal_count'] > row['away_team_goal_count']\n",
    "            else 'away winner' if row['home_team_goal_count'] < row['away_team_goal_count']\n",
    "            else 'draw'\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    mapping = {'home winner': 0, 'away winner': 1, 'draw': 2}\n",
    "    df['result_code'] = df['result'].map(mapping)\n",
    "\n",
    "    df = df.drop(columns=['result','home_team_goal_count','away_team_goal_count'], axis=1) \n",
    "\n",
    "    return df, mapping\n",
    "\n",
    "def dummie_categorical_values_fixed(df):\n",
    "    dummies_variables = pd.get_dummies(df, columns=['home_team_name', 'away_team_name'], drop_first=True, dtype=int) # Added dtype=int\n",
    "    return dummies_variables\n",
    "\n",
    "def clean_column_names(df):\n",
    "    def clean_name(name):\n",
    "        name = str(name).lower() # Ensure name is string\n",
    "        name = name.replace(' ', '_')\n",
    "        name = ''.join(\n",
    "            (c for c in unicodedata.normalize('NFD', name) \n",
    "            if unicodedata.category(c) != 'Mn')\n",
    "        )\n",
    "        name = re.sub(r'\\W+', '_', name)\n",
    "        return name\n",
    "    df.columns = [clean_name(col) for col in df.columns]\n",
    "    return df\n",
    "\n",
    "def get_relevant_features(df):\n",
    "    df_subset = df[['home_team_name', 'away_team_name','home_team_goal_count', 'away_team_goal_count', 'away_team_red_cards', 'home_team_shots', 'home_team_shots_on_target', 'away_team_shots_on_target', 'away_team_fouls']].copy()\n",
    "    return df_subset\n",
    "\n",
    "def get_train_test_data():\n",
    "    df_raw = get_csv_data()\n",
    "    df_features = get_relevant_features(df_raw)\n",
    "    df_features, actual_mapping = define_target_variable(df_features)\n",
    "    df_features = dummie_categorical_values_fixed(df_features)\n",
    "    df_features = clean_column_names(df_features)\n",
    "    return df_features, actual_mapping\n",
    "\n",
    "# --- New XGBoost function ---\n",
    "def train_and_tune_xgboost(df_processed):\n",
    "    \"\"\"\n",
    "    Trains an XGBoost classifier, finds the best hyperparameters using GridSearchCV,\n",
    "    and prints the results.\n",
    "\n",
    "    Args:\n",
    "        df_processed (pd.DataFrame): The preprocessed DataFrame with features and target.\n",
    "\n",
    "    Returns:\n",
    "        xgboost.XGBClassifier: The best trained XGBoost model.\n",
    "    \"\"\"\n",
    "    # 1. Separate features (X) and target (y)\n",
    "    # Ensure 'result_code' is not in X and is the target\n",
    "    if 'result_code' not in df_processed.columns:\n",
    "        raise ValueError(\"Target column 'result_code' not found in DataFrame.\")\n",
    "    \n",
    "    if 'result' in df_processed.columns:\n",
    "        X = df_processed.drop(['result_code', 'result'], axis=1)\n",
    "    else:\n",
    "        X = df_processed.drop('result_code', axis=1)\n",
    "        \n",
    "    y = df_processed['result_code']\n",
    "    X.columns = [str(col) for col in X.columns]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    print(f\"Training set shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
    "    print(f\"Test set shape: X_test={X_test.shape}, y_test={y_test.shape}\")\n",
    "    print(f\"Training target distribution:\\n{y_train.value_counts(normalize=True)}\")\n",
    "    print(f\"Test target distribution:\\n{y_test.value_counts(normalize=True)}\")\n",
    "\n",
    "\n",
    "    # Expanded parameter grid [1]\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.01, 0.05, 0.1],         # Smaller learning rates often require more n_estimators\n",
    "        'max_depth': [3, 5, 7, 9],                  # Maximum depth of a tree\n",
    "        'n_estimators': [100, 200, 300, 400, 500],  # Number of boosting rounds/trees\n",
    "        'subsample': [0.6, 0.7, 0.8, 0.9],           # Fraction of samples used for fitting the individual base learners\n",
    "        'colsample_bytree': [0.6, 0.7, 0.8, 0.9],    # Fraction of features used for fitting the individual base learners\n",
    "        'gamma': [0, 0.1, 0.2, 0.3],                 # Minimum loss reduction required to make a further partition\n",
    "        'min_child_weight': [1, 3, 5],               # Minimum sum of instance weight (hessian) needed in a child\n",
    "        'reg_alpha': [0, 0.01, 0.1, 0.5, 1],         # L1 regularization term on weights\n",
    "        'reg_lambda': [0.1, 0.5, 1, 1.5, 2]          # L2 regularization term on weights\n",
    "        # 'scale_pos_weight': [1, 2, 3] # See note below regarding this parameter for multi-class\n",
    "    }\n",
    "    # Note on scale_pos_weight for multi-class:\n",
    "    # The 'scale_pos_weight' parameter is primarily designed for binary classification or when one class\n",
    "    # is disproportionately important. For multi-class problems like yours (3 classes), its behavior\n",
    "    # in XGBoost's scikit-learn wrapper can be complex, potentially boosting only one class relative\n",
    "    # to others. Given your class imbalance (home winner: 0.57, away winner: 0.44, draw: 0.36 from\n",
    "    # previous precision), other methods like computing class weights for the 'sample_weight'\n",
    "    # parameter in fit(), or using SMOTE, might be more targeted for multi-class imbalance.\n",
    "    # If you want to experiment, you can add it, but carefully observe its impact on all classes.\n",
    "    # Example values from your dataset distribution:\n",
    "    # total_samples = len(y_train)\n",
    "    # count_home_winner = (y_train == 0).sum()\n",
    "    # count_away_winner = (y_train == 1).sum()\n",
    "    # count_draw = (y_train == 2).sum()\n",
    "    # A simple scale_pos_weight for 'away winner' (class 1) vs others might be:\n",
    "    # (total_samples - count_away_winner) / count_away_winner if you were treating it as binary.\n",
    "    # For now, it's commented out to simplify, but you can add it to the grid if you wish to explore.\n",
    "\n",
    "    num_class = len(y.unique())\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        objective='multi:softmax',\n",
    "        num_class=num_class,\n",
    "        use_label_encoder=False,  # Suppress warning for newer XGBoost versions\n",
    "        eval_metric='mlogloss',   # Evaluation metric for multi-class classification\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Adjust cv and n_jobs based on your computational power\n",
    "    # cv=5 is a common choice for more robust cross-validation.\n",
    "    # n_jobs=-1 will use all available CPU cores.\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=xgb_model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='accuracy', # You could also try 'f1_macro' or 'f1_weighted' given class imbalance\n",
    "        cv=3,  # Increase to 5 if you have time/power for more robust evaluation\n",
    "        n_jobs=-1, # Use all available cores\n",
    "        verbose=2  # Set to 1 for less output, 2 for more detailed updates\n",
    "    )\n",
    "\n",
    "    print(\"\\nStarting GridSearchCV with expanded hyperparameter grid...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nGridSearchCV finished.\")\n",
    "    print(f\"Best cross-validation score (accuracy): {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "\n",
    "    best_xgb_model = grid_search.best_estimator_\n",
    "    y_pred_test = best_xgb_model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    print(f\"\\nAccuracy of the best model on the test set: {test_accuracy:.4f}\")\n",
    "\n",
    "    print(\"\\nClassification Report on Test Set:\")\n",
    "    # Ensure your target_names match the mapping: {'home winner': 0, 'away winner': 1, 'draw': 2}\n",
    "    target_names = sorted(mapping, key=mapping.get) # Dynamically get target names in order of codes\n",
    "    print(classification_report(y_test, y_pred_test, target_names=target_names))\n",
    "\n",
    "    return best_xgb_model\n",
    "\n",
    "# --- How to use it ---\n",
    "if __name__ == '__main__':\n",
    "    # First, get your preprocessed data\n",
    "    df_processed_data, class_mapping_used = get_train_test_data()\n",
    "    \n",
    "    # Clean column names again after dummification as new columns are added\n",
    "    df_processed_data = clean_column_names(df_processed_data) \n",
    "\n",
    "    print(\"\\nPreprocessed DataFrame head:\")\n",
    "    print(df_processed_data.head())\n",
    "    print(f\"\\nShape of preprocessed DataFrame: {df_processed_data.shape}\")\n",
    "    print(f\"\\nColumns in preprocessed DataFrame: {df_processed_data.columns.tolist()}\")\n",
    "    \n",
    "    if 'result_code' in df_processed_data.columns:\n",
    "        print(f\"\\nValue counts for target 'result_code':\\n{df_processed_data['result_code'].value_counts()}\")\n",
    "        \n",
    "        # Now, run the XGBoost training and tuning function\n",
    "        best_model = train_and_tune_xgboost(df_processed_data,class_mapping_used)\n",
    "        \n",
    "        # The 'best_model' can now be used for further predictions or saved\n",
    "        # For example, to save the model:\n",
    "        # best_model.save_model(\"best_xgboost_model.json\") # [3]\n",
    "        print(\"\\nBest XGBoost model training and tuning complete.\")\n",
    "    else:\n",
    "        print(\"\\nError: 'result_code' column not found in the preprocessed data. Cannot proceed with XGBoost training.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
